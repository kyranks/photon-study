{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4065086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mine\n",
    "import uproot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boost_histogram as bh\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import gc\n",
    "# import atlasplots as ap\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "138ec1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 01:39:27.578470: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cvmfs/sft.cern.ch/lcg/releases/MCGenerators/thepeg/2.2.3-6fa5c/x86_64-centos7-gcc11-opt/lib/ThePEG:/cvmfs/sft.cern.ch/lcg/releases/MCGenerators/herwig++/7.2.3-c1d8e/x86_64-centos7-gcc11-opt/lib/Herwig:/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/jaxlib/mlir/_mlir_libs:/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/torch/lib:/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/onnxruntime/capi/:/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow:/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow/contrib/tensor_forest:/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow/python/framework:/cvmfs/sft.cern.ch/lcg/releases/java/11.0.14p1-8284a/x86_64-centos7-gcc11-opt/jre/lib/amd64:/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib64:/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/11.3.0-ad0f5/x86_64-centos7/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/11.3.0-ad0f5/x86_64-centos7/lib64:/cvmfs/sft.cern.ch/lcg/releases/binutils/2.37-355ed/x86_64-centos7/lib:/usr/local/lib/:/cvmfs/sft.cern.ch/lcg/releases/R/4.1.2-23baf/x86_64-centos7-gcc11-opt/lib64/R/library/readr/rcon\n",
      "2023-07-28 01:39:27.578515: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.28/00\n"
     ]
    }
   ],
   "source": [
    "#John's\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from datetime import datetime\n",
    "import statistics as stat\n",
    "import ROOT\n",
    "now = datetime.utcnow().strftime(\"%y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b61f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "# setting path\n",
    "sys.path.append('..')\n",
    " \n",
    "# importing\n",
    "import atlasplots as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81282fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mc20_clean = pickle.load(open('../picklefiles/df_mc20_clean.pickle', 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "# #converted and unconverted\n",
    "# df_conv = df_mc20_clean[df_mc20_clean.y_truth_convType == 0]\n",
    "# df_conv.index = list(range(len(df_conv))) #resetting indicies\n",
    "# df_unconv = df_mc20_clean[df_mc20_clean.y_truth_convType == 1]\n",
    "# df_unconv.index = list(range(len(df_unconv))) #resetting indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8669d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #SEPARATING EVEN AND ODD\n",
    "\n",
    "# def evenodd(df_name):\n",
    "#     '''separates input dataframe df_name into even events and odd events, by index'''\n",
    "#     evenlist = []\n",
    "#     oddlist = []\n",
    "#     for i in range(len(df_name)):\n",
    "# #         print(i)\n",
    "#         if i%2 == 0:\n",
    "#             evenlist.append(i)\n",
    "#         else:\n",
    "#             oddlist.append(i)\n",
    "            \n",
    "#     even = df_name.loc[evenlist]\n",
    "#     odd =  df_name.loc[oddlist]\n",
    "    \n",
    "#     return even, odd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "636e6d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_evenc,df_oddc = evenodd(df_conv)\n",
    "# df_evenu, df_oddu = evenodd(df_unconv)\n",
    "\n",
    "# df_evenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4398588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'full_v01'\n",
    "converted = True   #False for unconverted, True for converted    ##ACTUALLY FIX THIS TO DO SOMETHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b7a8805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_evenc = pickle.load(open('../picklefiles/'+version+'df_mc20_conv_even.pickle', 'rb'))\n",
    "# df_oddc = pickle.load(open('../picklefiles/'+version+'df_mc20_conv_odd.pickle', 'rb'))\n",
    "# df_evenu = pickle.load(open('../picklefiles/'+version+'df_mc20_unconv_even.pickle', 'rb'))\n",
    "# df_oddu = pickle.load(open('../picklefiles/'+version+'df_mc20_unconv_odd.pickle', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa6b94cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/'+version+'_ec1mil_a.pickle', 'rb') as file:\n",
    "    df_a = pickle.load(file)\n",
    "    file.close()\n",
    "\n",
    "with open('data/'+version+'_ec1mil_z.pickle', 'rb') as file:\n",
    "    df_z = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee377276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_a[~df_a.y_isTruthMatchedPhoton]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69354964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TAKING JUST FIRST 100000 EVENTS\n",
    "df_oddcsig = df_z[df_z.y_isTruthMatchedPhoton].iloc[-50000:]   # using end of df_even instead of importing another file\n",
    "df_oddcbkg = df_z[~df_z.y_isTruthMatchedPhoton].iloc[-50000:]\n",
    "df_evencsig = df_a[df_a.y_isTruthMatchedPhoton].iloc[:50000]\n",
    "df_evencbkg = df_a[~df_a.y_isTruthMatchedPhoton].iloc[:50000]\n",
    "\n",
    "# df_oddc = df_oddc.iloc[:100000]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fba0c709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate\n",
    "df_oddc = pd.concat([df_oddcsig,df_oddcbkg])\n",
    "df_evenc = pd.concat([df_evencsig,df_evencbkg])\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bee24ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle\n",
    "df_oddc = df_oddc.sample(frac=1).reset_index(drop=True)    #shuffling and resetting indices\n",
    "df_evenc = df_evenc.sample(frac=1).reset_index(drop=True)    #shuffling and resetting indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9d3ce14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mcTotWeight</th>\n",
       "      <th>goodWeight</th>\n",
       "      <th>finalWeight</th>\n",
       "      <th>y_pt</th>\n",
       "      <th>y_eta</th>\n",
       "      <th>y_isTruthMatchedPhoton</th>\n",
       "      <th>y_convType</th>\n",
       "      <th>HadLeakage</th>\n",
       "      <th>y_Reta</th>\n",
       "      <th>y_weta2</th>\n",
       "      <th>...</th>\n",
       "      <th>HadLeakage_stand</th>\n",
       "      <th>y_Reta_stand</th>\n",
       "      <th>y_Rphi_stand</th>\n",
       "      <th>y_weta2_stand</th>\n",
       "      <th>y_wtots1_stand</th>\n",
       "      <th>y_weta1_stand</th>\n",
       "      <th>y_fracs1_stand</th>\n",
       "      <th>y_deltae_stand</th>\n",
       "      <th>y_Eratio_stand</th>\n",
       "      <th>y_f1_stand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96.567696</td>\n",
       "      <td>0.039965</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.004008</td>\n",
       "      <td>0.967235</td>\n",
       "      <td>0.009021</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.261930</td>\n",
       "      <td>0.382433</td>\n",
       "      <td>0.071863</td>\n",
       "      <td>-0.855433</td>\n",
       "      <td>0.081235</td>\n",
       "      <td>0.021937</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.165607</td>\n",
       "      <td>0.417216</td>\n",
       "      <td>1.568672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.501375</td>\n",
       "      <td>5.452043</td>\n",
       "      <td>792.348624</td>\n",
       "      <td>77.997223</td>\n",
       "      <td>0.184313</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>0.961996</td>\n",
       "      <td>0.009084</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147656</td>\n",
       "      <td>0.303400</td>\n",
       "      <td>0.146252</td>\n",
       "      <td>-0.808492</td>\n",
       "      <td>0.080476</td>\n",
       "      <td>0.019623</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>-0.180193</td>\n",
       "      <td>0.374817</td>\n",
       "      <td>0.322142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.322744</td>\n",
       "      <td>7.359913</td>\n",
       "      <td>1151.416064</td>\n",
       "      <td>55.880653</td>\n",
       "      <td>2.289395</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002076</td>\n",
       "      <td>0.938835</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.181389</td>\n",
       "      <td>-0.045995</td>\n",
       "      <td>-0.029954</td>\n",
       "      <td>1.171828</td>\n",
       "      <td>0.079972</td>\n",
       "      <td>0.018903</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>-0.168376</td>\n",
       "      <td>0.470836</td>\n",
       "      <td>0.091723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11353.638395</td>\n",
       "      <td>11186.365807</td>\n",
       "      <td>11186.365807</td>\n",
       "      <td>33.690964</td>\n",
       "      <td>0.706565</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.036542</td>\n",
       "      <td>0.675610</td>\n",
       "      <td>0.011016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274893</td>\n",
       "      <td>-4.016801</td>\n",
       "      <td>-0.166297</td>\n",
       "      <td>0.628286</td>\n",
       "      <td>0.082052</td>\n",
       "      <td>0.026592</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>-0.002955</td>\n",
       "      <td>-3.159546</td>\n",
       "      <td>0.649553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.563264</td>\n",
       "      <td>11.574293</td>\n",
       "      <td>1553.399326</td>\n",
       "      <td>55.084892</td>\n",
       "      <td>-0.258573</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010270</td>\n",
       "      <td>0.954219</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072917</td>\n",
       "      <td>0.186089</td>\n",
       "      <td>0.110494</td>\n",
       "      <td>-0.379231</td>\n",
       "      <td>0.080758</td>\n",
       "      <td>0.020720</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>-0.116585</td>\n",
       "      <td>0.376915</td>\n",
       "      <td>0.941914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0.003820</td>\n",
       "      <td>0.003820</td>\n",
       "      <td>0.652571</td>\n",
       "      <td>528.260986</td>\n",
       "      <td>-0.769436</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011799</td>\n",
       "      <td>0.941893</td>\n",
       "      <td>0.008657</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052677</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.119195</td>\n",
       "      <td>-1.126005</td>\n",
       "      <td>0.081135</td>\n",
       "      <td>0.020481</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.136240</td>\n",
       "      <td>0.427889</td>\n",
       "      <td>-0.137110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>14107.153674</td>\n",
       "      <td>13874.585958</td>\n",
       "      <td>13874.585958</td>\n",
       "      <td>46.292999</td>\n",
       "      <td>-1.675368</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.156212</td>\n",
       "      <td>0.856110</td>\n",
       "      <td>0.013924</td>\n",
       "      <td>...</td>\n",
       "      <td>1.859163</td>\n",
       "      <td>-1.293918</td>\n",
       "      <td>-0.200770</td>\n",
       "      <td>2.790610</td>\n",
       "      <td>0.086789</td>\n",
       "      <td>0.024978</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.976051</td>\n",
       "      <td>-4.414635</td>\n",
       "      <td>-0.040762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>23.611248</td>\n",
       "      <td>23.351048</td>\n",
       "      <td>2289.156035</td>\n",
       "      <td>37.703594</td>\n",
       "      <td>0.595123</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000689</td>\n",
       "      <td>0.978633</td>\n",
       "      <td>0.008897</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218002</td>\n",
       "      <td>0.554378</td>\n",
       "      <td>-0.236786</td>\n",
       "      <td>-0.948160</td>\n",
       "      <td>0.081136</td>\n",
       "      <td>0.017232</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.151114</td>\n",
       "      <td>0.355465</td>\n",
       "      <td>1.411193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>19886.833751</td>\n",
       "      <td>19898.216044</td>\n",
       "      <td>19898.216044</td>\n",
       "      <td>25.063526</td>\n",
       "      <td>2.053412</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.080368</td>\n",
       "      <td>0.575115</td>\n",
       "      <td>0.013162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855089</td>\n",
       "      <td>-5.532800</td>\n",
       "      <td>-0.529965</td>\n",
       "      <td>2.224397</td>\n",
       "      <td>0.082183</td>\n",
       "      <td>0.024416</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>1.586114</td>\n",
       "      <td>-4.154555</td>\n",
       "      <td>2.052301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>7.905829</td>\n",
       "      <td>7.978501</td>\n",
       "      <td>1070.803837</td>\n",
       "      <td>53.391159</td>\n",
       "      <td>-0.060290</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.968944</td>\n",
       "      <td>0.009492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155913</td>\n",
       "      <td>0.408218</td>\n",
       "      <td>0.097963</td>\n",
       "      <td>-0.505629</td>\n",
       "      <td>0.080760</td>\n",
       "      <td>0.019496</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>-0.139307</td>\n",
       "      <td>0.370292</td>\n",
       "      <td>0.476014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mcTotWeight    goodWeight   finalWeight        y_pt     y_eta  \\\n",
       "0          0.000000      0.000000      0.000000   96.567696  0.039965   \n",
       "1          5.501375      5.452043    792.348624   77.997223  0.184313   \n",
       "2          7.322744      7.359913   1151.416064   55.880653  2.289395   \n",
       "3      11353.638395  11186.365807  11186.365807   33.690964  0.706565   \n",
       "4         11.563264     11.574293   1553.399326   55.084892 -0.258573   \n",
       "...             ...           ...           ...         ...       ...   \n",
       "99995      0.003820      0.003820      0.652571  528.260986 -0.769436   \n",
       "99996  14107.153674  13874.585958  13874.585958   46.292999 -1.675368   \n",
       "99997     23.611248     23.351048   2289.156035   37.703594  0.595123   \n",
       "99998  19886.833751  19898.216044  19898.216044   25.063526  2.053412   \n",
       "99999      7.905829      7.978501   1070.803837   53.391159 -0.060290   \n",
       "\n",
       "       y_isTruthMatchedPhoton  y_convType  HadLeakage    y_Reta   y_weta2  \\\n",
       "0                        True           3   -0.004008  0.967235  0.009021   \n",
       "1                        True           3    0.004624  0.961996  0.009084   \n",
       "2                        True           3    0.002076  0.938835  0.011747   \n",
       "3                       False           1    0.036542  0.675610  0.011016   \n",
       "4                        True           3    0.010270  0.954219  0.009662   \n",
       "...                       ...         ...         ...       ...       ...   \n",
       "99995                    True           5    0.011799  0.941893  0.008657   \n",
       "99996                   False           3    0.156212  0.856110  0.013924   \n",
       "99997                    True           4   -0.000689  0.978633  0.008897   \n",
       "99998                   False           1    0.080368  0.575115  0.013162   \n",
       "99999                    True           2    0.004001  0.968944  0.009492   \n",
       "\n",
       "       ...  HadLeakage_stand  y_Reta_stand  y_Rphi_stand  y_weta2_stand  \\\n",
       "0      ...         -0.261930      0.382433      0.071863      -0.855433   \n",
       "1      ...         -0.147656      0.303400      0.146252      -0.808492   \n",
       "2      ...         -0.181389     -0.045995     -0.029954       1.171828   \n",
       "3      ...          0.274893     -4.016801     -0.166297       0.628286   \n",
       "4      ...         -0.072917      0.186089      0.110494      -0.379231   \n",
       "...    ...               ...           ...           ...            ...   \n",
       "99995  ...         -0.052677      0.000138      0.119195      -1.126005   \n",
       "99996  ...          1.859163     -1.293918     -0.200770       2.790610   \n",
       "99997  ...         -0.218002      0.554378     -0.236786      -0.948160   \n",
       "99998  ...          0.855089     -5.532800     -0.529965       2.224397   \n",
       "99999  ...         -0.155913      0.408218      0.097963      -0.505629   \n",
       "\n",
       "       y_wtots1_stand  y_weta1_stand  y_fracs1_stand  y_deltae_stand  \\\n",
       "0            0.081235       0.021937        0.000008       -0.165607   \n",
       "1            0.080476       0.019623       -0.000098       -0.180193   \n",
       "2            0.079972       0.018903       -0.000148       -0.168376   \n",
       "3            0.082052       0.026592        0.000686       -0.002955   \n",
       "4            0.080758       0.020720       -0.000102       -0.116585   \n",
       "...               ...            ...             ...             ...   \n",
       "99995        0.081135       0.020481       -0.000043       -0.136240   \n",
       "99996        0.086789       0.024978        0.000359        0.976051   \n",
       "99997        0.081136       0.017232        0.000012       -0.151114   \n",
       "99998        0.082183       0.024416        0.000777        1.586114   \n",
       "99999        0.080760       0.019496       -0.000023       -0.139307   \n",
       "\n",
       "       y_Eratio_stand  y_f1_stand  \n",
       "0            0.417216    1.568672  \n",
       "1            0.374817    0.322142  \n",
       "2            0.470836    0.091723  \n",
       "3           -3.159546    0.649553  \n",
       "4            0.376915    0.941914  \n",
       "...               ...         ...  \n",
       "99995        0.427889   -0.137110  \n",
       "99996       -4.414635   -0.040762  \n",
       "99997        0.355465    1.411193  \n",
       "99998       -4.154555    2.052301  \n",
       "99999        0.370292    0.476014  \n",
       "\n",
       "[100000 rows x 27 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93983168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9005e3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_stand = ['HadLeakage_stand', 'y_Reta_stand', 'y_Rphi_stand', 'y_weta2_stand',\n",
    "                   'y_wtots1_stand', 'y_weta1_stand', 'y_fracs1_stand', 'y_deltae_stand',\n",
    "                   'y_Eratio_stand', 'y_f1_stand']\n",
    "features = ['HadLeakage', 'y_Reta', 'y_weta2', 'y_Rphi', 'y_wtots1', \n",
    "            'y_weta1', 'y_fracs1', 'y_deltae', 'y_Eratio', 'y_f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "562bc1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new weight that equalizes number of signal and bkg weighted counts\n",
    "evensigsum = sum(df_evenc[df_evenc.y_isTruthMatchedPhoton].finalWeight)\n",
    "evenbkgsum = sum(df_evenc[~df_evenc.y_isTruthMatchedPhoton].finalWeight)\n",
    "oddsigsum = sum(df_oddc[df_oddc.y_isTruthMatchedPhoton].finalWeight)\n",
    "oddbkgsum = sum(df_oddc[~df_oddc.y_isTruthMatchedPhoton].finalWeight)\n",
    "\n",
    "evenratio = evenbkgsum/evensigsum\n",
    "oddratio = oddbkgsum/oddsigsum\n",
    "\n",
    "even_equ = evenratio*np.array(df_evenc.y_isTruthMatchedPhoton*1)\n",
    "even_equ[even_equ==0] = 1.\n",
    "odd_equ = oddratio*np.array(df_oddc.y_isTruthMatchedPhoton*1)\n",
    "odd_equ[odd_equ==0] = 1.\n",
    "\n",
    "df_evenc['equWeight'] = np.multiply(even_equ,np.array(df_evenc['finalWeight']))\n",
    "df_oddc['equWeight'] = np.multiply(odd_equ,np.array(df_evenc['finalWeight']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b9b7d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR NOW just doing **unconv.**  variables\n",
    "featlist = features_stand   # either features or features_stand \n",
    "weightstr = 'equWeight'   #either 'finalWeight' for E_T and eta weighting or 'goodWeight' for not\n",
    "\n",
    "\n",
    "# for unconverted. (##add in option to change later)\n",
    "train_features_even = np.array(df_evenc[featlist])\n",
    "train_labels_even   = np.array(df_evenc['y_isTruthMatchedPhoton'])\n",
    "train_weights_even  = np.array(df_evenc[weightstr])\n",
    "test_features_even = np.array(df_oddc[featlist])\n",
    "test_labels_even   = np.array(df_oddc['y_isTruthMatchedPhoton'])\n",
    "test_weights_even  = np.array(df_oddc[weightstr])\n",
    "\n",
    "train_features_odd = np.array(df_oddc[featlist])\n",
    "train_labels_odd   = np.array(df_oddc['y_isTruthMatchedPhoton'])\n",
    "train_weights_odd  = np.array(df_oddc[weightstr])\n",
    "test_features_odd = np.array(df_evenc[featlist])\n",
    "test_labels_odd   = np.array(df_evenc['y_isTruthMatchedPhoton'])\n",
    "test_weights_odd  = np.array(df_evenc[weightstr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06c8a4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_even.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5caeca78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(train_labels_even)/len(train_labels_even), np.sum(test_labels_even)/len(test_labels_even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3678f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49999999999999667"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with weights\n",
    "np.sum(np.multiply(train_labels_even*1,train_weights_even))/np.sum(train_weights_even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82aeee10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_features,train_labels,train_weights,valid_features,valid_labels,valid_weights):\n",
    "    \"\"\"\n",
    "    Trains a binary classification model using the provided training and validation data.\n",
    "\n",
    "    Args:\n",
    "        train_features (numpy.ndarray): The input features for training the model.\n",
    "        train_labels (numpy.ndarray): The target labels for training the model.\n",
    "        train_weights (numpy.ndarray): The sample weights for training the model.\n",
    "        valid_features (numpy.ndarray): The input features for validating the model.\n",
    "        valid_labels (numpy.ndarray): The target labels for validating the model.\n",
    "        valid_weights (numpy.ndarray): The sample weights for validating the model.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the trained model and a dictionary of loss and accuracy values during training.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = tf.keras.layers.Input(dtype=tf.float64,shape=(train_features.shape[1],))\n",
    "    Dx = inputs\n",
    "    Dx = tf.keras.layers.BatchNormalization()(Dx)\n",
    "    Dx = tf.keras.layers.Dense(512,input_shape = (train_features.shape[1],))(Dx)\n",
    "    Dx = tf.keras.layers.LeakyReLU()(Dx)\n",
    "    Dx = tf.keras.layers.Dense(512,input_shape = (train_features.shape[1],))(Dx)\n",
    "    Dx = tf.keras.layers.LeakyReLU()(Dx)\n",
    "    Dx = tf.keras.layers.Dense(512,input_shape = (train_features.shape[1],))(Dx)\n",
    "    Dx = tf.keras.layers.Dense(1,activation=\"sigmoid\")(Dx)\n",
    "    f = tf.keras.models.Model([inputs],[Dx])\n",
    "\n",
    "    print('Classifier Summary')\n",
    "    f.summary()\n",
    "\n",
    "    ###########################################\n",
    "    # Train model\n",
    "    ############################################\n",
    "    f.compile(loss = tf.keras.losses.binary_crossentropy, optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5),metrics=[\"accuracy\"])\n",
    "\n",
    "    callback_es = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience = 10)\n",
    "    callback_nan = tf.keras.callbacks.TerminateOnNaN()\n",
    "\n",
    "    losses = {\"train\":[],\"accuracy\":[],\"validation\":[]}\n",
    "    hist = f.fit(x=train_features,\n",
    "           y=train_labels,\n",
    "           sample_weight=np.abs(train_weights),\n",
    "           callbacks=[callback_nan,callback_es],\n",
    "           batch_size=256,\n",
    "           epochs=200,\n",
    "           verbose=1,\n",
    "           validation_data=(valid_features,valid_labels,np.abs(valid_weights)))\n",
    "    losses[\"train\"].append(hist.history['loss'])\n",
    "    losses[\"accuracy\"].append(hist.history['accuracy'])\n",
    "    losses[\"validation\"].append(hist.history['val_loss'])\n",
    "\n",
    "    return f,losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75e0bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(losses,name,label):\n",
    "    \"\"\"\n",
    "    Plots the training and validation losses over epochs.\n",
    "\n",
    "    Args:\n",
    "        losses (dict): A dictionary containing the training and validation losses.\n",
    "        name (str): The name of the plot file to be saved.\n",
    "        label (str): The label for the plot.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    train_losses = losses['train']\n",
    "    validation_losses = losses['validation']\n",
    "    fig1, ax1 = plt.subplots(1)\n",
    "    plt.plot(range(len(train_losses[0])), train_losses[0], color=\"blue\",label=\"Training Loss\")\n",
    "    plt.plot(range(len(validation_losses[0])), validation_losses[0],color=\"red\",label='Validation Loss')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.title.set_text(label)\n",
    "    ax1.text(0.85, 0.77, 'ATLAS Internal', weight='bold',horizontalalignment='center', verticalalignment='center', transform=ax1.transAxes)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    fig1.savefig(\"plots/\"+name+\".pdf\",bbox_inches='tight')\n",
    "    plt.clf()\n",
    "    plt.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03913fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(model,test_features,test_labels,name,label):\n",
    "    \"\"\"\n",
    "    Plots the Receiver Operating Characteristic (ROC) curve for a binary classification model.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): The trained model used for prediction.\n",
    "        test_features (numpy.ndarray): The input features for testing the model.\n",
    "        test_labels (numpy.ndarray): The true labels for the test data.\n",
    "        name (str): The name of the plot file to be saved.\n",
    "        label (str): The label for the plot.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Raises:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(test_features).ravel()\n",
    "\n",
    "    # Compute the false positive rate, true positive rate, and thresholds for the ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(test_labels,y_pred)\n",
    "\n",
    "    f,ax = plt.subplots(1)\n",
    "    plt.plot([1,0],[0,1],'k--')\n",
    "    plt.plot(1-fpr, tpr)\n",
    "    plt.xlabel('Bkg Rejection')\n",
    "    plt.ylabel('Signal Efficiency')\n",
    "    plt.title(label)\n",
    "    plt.text(0.85, 0.95, 'ATLAS Internal', weight='bold',horizontalalignment='center', verticalalignment='center')\n",
    "    #plt.show()\n",
    "    f.savefig(\"plots/\"+name+\".pdf\",bbox_inches='tight')\n",
    "    plt.clf()\n",
    "    plt.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1d5d337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_plot(model,test_features,train_features,train_labels,test_labels,train_weights,test_weights,name):\n",
    "    \"\"\"\n",
    "    Creates a validation plot comparing the output of a neural network model for signal and background events.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): The trained model used for prediction.\n",
    "        test_features (numpy.ndarray): The input features for testing the model.\n",
    "        train_features (numpy.ndarray): The input features for training the model.\n",
    "        train_labels (numpy.ndarray): The target labels for training the model.\n",
    "        test_labels (numpy.ndarray): The target labels for testing the model.\n",
    "        train_weights (numpy.ndarray): The sample weights for training the model.\n",
    "        test_weights (numpy.ndarray): The sample weights for testing the model.\n",
    "        name (str): The name of the plot file to be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Raises:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(test_features).ravel()\n",
    "    y_pred_train = model.predict(train_features).ravel()\n",
    "    ROOT.gStyle.SetOptStat(0)\n",
    "    hist_sig = ROOT.TH1F(\"h_sig\",\";NN output; Normalized Events\",21,0,1.1)\n",
    "    hist_bkg = ROOT.TH1F(\"h_bkg\",\";NN output;Normalized Events\",21,0,1.1)\n",
    "    hist_sig_train = ROOT.TH1F(\"h_sig_train\",\"NN output;Normalized Events\",21,0,1.1)\n",
    "    hist_bkg_train = ROOT.TH1F(\"h_bkg_train\",\"NN output;Normalized Events\",21,0,1.1)\n",
    "\n",
    "    for i in range(len(test_features)):\n",
    "        if (test_labels[i]):\n",
    "            hist_sig.Fill(y_pred[i],test_weights[i])\n",
    "        else:\n",
    "            hist_bkg.Fill(y_pred[i],test_weights[i])\n",
    "\n",
    "    for i in range(len(train_features)):\n",
    "        if (train_labels[i]):\n",
    "            hist_sig_train.Fill(y_pred_train[i],train_weights[i])\n",
    "        else:\n",
    "            hist_bkg_train.Fill(y_pred_train[i],train_weights[i])\n",
    "\n",
    "    can = ROOT.TCanvas(\"can\",\"can\",800,600)\n",
    "\n",
    "    hist_sig.SetLineColor(1)\n",
    "    hist_sig.SetFillColor(1)\n",
    "    hist_sig.SetFillStyle(3005)\n",
    "    hist_sig.SetMarkerStyle(0)\n",
    "    hist_bkg.SetLineColor(8)\n",
    "    hist_bkg.SetFillColor(8)\n",
    "    hist_bkg.SetMarkerStyle(0)\n",
    "    hist_sig_train.SetMarkerColor(1)\n",
    "    hist_sig_train.SetLineColor(1)\n",
    "    hist_sig_train.SetMarkerSize(1)\n",
    "    hist_sig_train.SetMarkerStyle(8)\n",
    "    hist_bkg_train.SetMarkerColor(209)\n",
    "    hist_bkg_train.SetLineColor(209)\n",
    "    hist_bkg_train.SetMarkerStyle(8)\n",
    "    h = hist_bkg.DrawNormalized(\"HIST E\")\n",
    "    h.SetMinimum(0)\n",
    "    h.SetMaximum(h.GetMaximum()*3)\n",
    "    hist_sig.DrawNormalized(\"HIST SAME E\")\n",
    "    hist_bkg_train.DrawNormalized(\"pe SAME\")\n",
    "    hist_sig_train.DrawNormalized(\"pe SAME\")\n",
    "    leg = ROOT.TLegend(0.6,0.6,0.95,0.9)\n",
    "    leg.SetTextSize(.035)\n",
    "    leg.AddEntry(hist_sig_train,\"MC Signal (train)\",\"pe\")\n",
    "    leg.AddEntry(hist_bkg_train,\"MC Background (train)\",\"pe\")\n",
    "    leg.AddEntry(hist_sig,\"MC Signal (test)\",\"F\")\n",
    "    leg.AddEntry(hist_bkg,\"MC Background (test)\",\"F\")\n",
    "    leg.SetBorderSize(0)\n",
    "    leg.Draw()\n",
    "#     ROOT.ATLASLabel(0.2,0.88,\"Internal\");   \n",
    "    can.Print(\"plots/\"+name+\".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94638be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'train'\n",
    "outmodel = version+'conv_50000each_equWeight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "066b3a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Summary\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 10)               40        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               5632      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 531,497\n",
      "Trainable params: 531,477\n",
      "Non-trainable params: 20\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "391/391 [==============================] - 151s 378ms/step - loss: 7753.4370 - accuracy: 0.8755 - val_loss: 13669.8535 - val_accuracy: 0.8894\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 6375.7925 - accuracy: 0.8933 - val_loss: 11570.7354 - val_accuracy: 0.8943\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 28s 72ms/step - loss: 6165.9238 - accuracy: 0.8981 - val_loss: 11391.0859 - val_accuracy: 0.8963\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 6072.4092 - accuracy: 0.8996 - val_loss: 11232.1797 - val_accuracy: 0.9017\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 5961.9390 - accuracy: 0.9020 - val_loss: 10516.5635 - val_accuracy: 0.9031\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 5838.9800 - accuracy: 0.9051 - val_loss: 11235.6670 - val_accuracy: 0.9032\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 5774.4653 - accuracy: 0.9064 - val_loss: 10654.7676 - val_accuracy: 0.9056\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 25s 65ms/step - loss: 5739.6704 - accuracy: 0.9071 - val_loss: 10447.9805 - val_accuracy: 0.9097\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 25s 63ms/step - loss: 5748.0620 - accuracy: 0.9077 - val_loss: 10491.9492 - val_accuracy: 0.9052\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 5719.3799 - accuracy: 0.9085 - val_loss: 10916.5879 - val_accuracy: 0.9044\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 5713.1821 - accuracy: 0.9077 - val_loss: 10488.7100 - val_accuracy: 0.9065\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 5656.9414 - accuracy: 0.9085 - val_loss: 9941.3604 - val_accuracy: 0.9052\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 28s 70ms/step - loss: 5745.4629 - accuracy: 0.9084 - val_loss: 9913.5596 - val_accuracy: 0.9071\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 5681.8491 - accuracy: 0.9083 - val_loss: 9808.3477 - val_accuracy: 0.9069\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 5673.1699 - accuracy: 0.9085 - val_loss: 11280.8281 - val_accuracy: 0.9066\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 5664.3999 - accuracy: 0.9090 - val_loss: 9819.9756 - val_accuracy: 0.9056\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 5662.1436 - accuracy: 0.9086 - val_loss: 10109.9658 - val_accuracy: 0.9068\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 27s 68ms/step - loss: 5553.4009 - accuracy: 0.9089 - val_loss: 10514.2734 - val_accuracy: 0.9098\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 5601.8496 - accuracy: 0.9096 - val_loss: 11322.1328 - val_accuracy: 0.9086\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 5560.0947 - accuracy: 0.9084 - val_loss: 10445.8486 - val_accuracy: 0.9082\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 5596.3950 - accuracy: 0.9093 - val_loss: 10421.4971 - val_accuracy: 0.9060\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 29s 75ms/step - loss: 5578.1504 - accuracy: 0.9082 - val_loss: 10084.1465 - val_accuracy: 0.9103\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 5545.4590 - accuracy: 0.9097 - val_loss: 10045.6113 - val_accuracy: 0.9107\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 5584.2280 - accuracy: 0.9094 - val_loss: 10777.9824 - val_accuracy: 0.9074\n",
      "Classifier Summary\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               5632      \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 531,497\n",
      "Trainable params: 531,477\n",
      "Non-trainable params: 20\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "391/391 [==============================] - 165s 413ms/step - loss: 9690.8809 - accuracy: 0.8350 - val_loss: 8715.6738 - val_accuracy: 0.8549\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 6517.7593 - accuracy: 0.8591 - val_loss: 8211.4141 - val_accuracy: 0.8643\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 6251.4106 - accuracy: 0.8686 - val_loss: 8102.1069 - val_accuracy: 0.8649\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 6023.5181 - accuracy: 0.8749 - val_loss: 7774.2021 - val_accuracy: 0.8744\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 32s 81ms/step - loss: 5938.6060 - accuracy: 0.8803 - val_loss: 7638.0571 - val_accuracy: 0.8790\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 28s 72ms/step - loss: 5847.2173 - accuracy: 0.8832 - val_loss: 7270.7827 - val_accuracy: 0.8885\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 28s 72ms/step - loss: 5821.7915 - accuracy: 0.8866 - val_loss: 7368.1875 - val_accuracy: 0.8894\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 5800.3496 - accuracy: 0.8877 - val_loss: 7492.6426 - val_accuracy: 0.8878\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 24s 62ms/step - loss: 5751.6338 - accuracy: 0.8891 - val_loss: 7062.1567 - val_accuracy: 0.8931\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 25s 64ms/step - loss: 5713.2314 - accuracy: 0.8900 - val_loss: 6995.9194 - val_accuracy: 0.8930\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 27s 68ms/step - loss: 5693.8145 - accuracy: 0.8908 - val_loss: 7192.1016 - val_accuracy: 0.8926\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 5686.0229 - accuracy: 0.8908 - val_loss: 7246.5479 - val_accuracy: 0.8903\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 5677.6782 - accuracy: 0.8924 - val_loss: 7364.0186 - val_accuracy: 0.8896\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 32s 81ms/step - loss: 5698.5688 - accuracy: 0.8915 - val_loss: 7329.9609 - val_accuracy: 0.8913\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 5661.8721 - accuracy: 0.8919 - val_loss: 7374.8359 - val_accuracy: 0.8944\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 29s 75ms/step - loss: 5642.8179 - accuracy: 0.8939 - val_loss: 6973.8501 - val_accuracy: 0.9004\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 26s 68ms/step - loss: 5633.4575 - accuracy: 0.8938 - val_loss: 7199.2793 - val_accuracy: 0.8900\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 5613.2173 - accuracy: 0.8933 - val_loss: 7371.2871 - val_accuracy: 0.8919\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 25s 65ms/step - loss: 5629.7856 - accuracy: 0.8932 - val_loss: 7128.4946 - val_accuracy: 0.8961\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 25s 65ms/step - loss: 5591.5854 - accuracy: 0.8941 - val_loss: 6902.3672 - val_accuracy: 0.8997\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 31s 81ms/step - loss: 5632.2983 - accuracy: 0.8943 - val_loss: 7044.8628 - val_accuracy: 0.8975\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 5615.8306 - accuracy: 0.8952 - val_loss: 7500.6836 - val_accuracy: 0.8917\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 5564.6221 - accuracy: 0.8945 - val_loss: 7075.6621 - val_accuracy: 0.8960\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 28s 72ms/step - loss: 5614.4414 - accuracy: 0.8957 - val_loss: 7476.4482 - val_accuracy: 0.8865\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 30s 76ms/step - loss: 5582.7183 - accuracy: 0.8944 - val_loss: 7088.0840 - val_accuracy: 0.8953\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 5555.1636 - accuracy: 0.8959 - val_loss: 7612.7778 - val_accuracy: 0.8855\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 5562.0273 - accuracy: 0.8944 - val_loss: 6766.1519 - val_accuracy: 0.9028\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 5571.2539 - accuracy: 0.8958 - val_loss: 7167.5669 - val_accuracy: 0.8959\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 5537.3486 - accuracy: 0.8962 - val_loss: 7206.0337 - val_accuracy: 0.8930\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 5501.0054 - accuracy: 0.8959 - val_loss: 6953.7227 - val_accuracy: 0.9002\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 32s 82ms/step - loss: 5526.0884 - accuracy: 0.8961 - val_loss: 7441.2891 - val_accuracy: 0.8917\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 33s 83ms/step - loss: 5536.6196 - accuracy: 0.8961 - val_loss: 7292.1401 - val_accuracy: 0.8922\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 5468.1997 - accuracy: 0.8963 - val_loss: 7181.2231 - val_accuracy: 0.8956\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 5505.6826 - accuracy: 0.8970 - val_loss: 7240.4883 - val_accuracy: 0.8956\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 28s 70ms/step - loss: 5496.9502 - accuracy: 0.8964 - val_loss: 7160.3032 - val_accuracy: 0.8976\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 5494.1489 - accuracy: 0.8959 - val_loss: 6786.9805 - val_accuracy: 0.9023\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 5498.6265 - accuracy: 0.8963 - val_loss: 6980.3745 - val_accuracy: 0.9014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 01:47:42.878064: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cvmfs/sft.cern.ch/lcg/releases/MCGenerators/thepeg/2.2.3-6fa5c/x86_64-centos7-gcc11-opt/lib/ThePEG:/cvmfs/sft.cern.ch/lcg/releases/MCGenerators/herwig++/7.2.3-c1d8e/x86_64-centos7-gcc11-opt/lib/Herwig:/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/jaxlib/mlir/_mlir_libs:/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/torch/lib:/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/onnxruntime/capi/:/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow:/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow/contrib/tensor_forest:/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow/python/framework:/cvmfs/sft.cern.ch/lcg/releases/java/11.0.14p1-8284a/x86_64-centos7-gcc11-opt/jre/lib/amd64:/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib64:/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/11.3.0-ad0f5/x86_64-centos7/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/11.3.0-ad0f5/x86_64-centos7/lib64:/cvmfs/sft.cern.ch/lcg/releases/binutils/2.37-355ed/x86_64-centos7/lib:/usr/local/lib/:/cvmfs/sft.cern.ch/lcg/releases/R/4.1.2-23baf/x86_64-centos7-gcc11-opt/lib64/R/library/readr/rcon\n",
      "2023-07-28 01:47:42.878117: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-07-28 01:47:42.878168: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (8130324fe5c9): /proc/driver/nvidia/version does not exist\n",
      "2023-07-28 01:47:42.942786: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#actually using the functions\n",
    "if method == 'train':\n",
    "    f_even, losses_even = train_model(train_features_even,train_labels_even,train_weights_even,test_features_even,test_labels_even,test_weights_even)\n",
    "    f_odd, losses_odd = train_model(train_features_odd,train_labels_odd,train_weights_odd,test_features_odd,test_labels_odd,test_weights_odd)\n",
    "\n",
    "#     plot_losses(losses_even,outmodel+\"_losses_even\",\"Even NN\")\n",
    "#     plot_losses(losses_odd,outmodel+\"_losses_odd\",\"Odd NN\")\n",
    "#     plot_roc(f_even,test_features_even,test_labels_even,outmodel+\"_roc_even\",\"Even NN\")\n",
    "#     plot_roc(f_odd,test_features_odd,test_labels_odd,outmodel+\"_roc_odd\",\"Odd NN\")\n",
    "#     validation_plot(f_even,test_features_even,train_features_even,train_labels_even,test_labels_even,train_weights_even,test_weights_even,outmodel+\"_validation_even\")\n",
    "#     validation_plot(f_odd,test_features_odd,train_features_odd,train_labels_odd,test_labels_odd,train_weights_odd,test_weights_odd,outmodel+\"_validation_odd\")\n",
    "\n",
    "\n",
    "#     y_pred_even = f_even.predict(test_features_even).ravel()\n",
    "#     fpr_even, tpr_even, thresholds_even = roc_curve(test_labels_even,y_pred_even)\n",
    "#     auc_nom_even = auc(fpr_even,tpr_even)\n",
    "\n",
    "#     y_pred_odd = f_odd.predict(test_features_odd).ravel()\n",
    "#     fpr_odd, tpr_odd, thresholds_odd = roc_curve(test_labels_odd,y_pred_odd)\n",
    "#     auc_nom_odd = auc(fpr_odd,tpr_odd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "411282ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Info in <TCanvas::Print>: pdf file plots/full_v01conv_50000each_equWeight_validation_even.pdf has been created\n",
      "Info in <TCanvas::Print>: pdf file plots/full_v01conv_50000each_equWeight_validation_odd.pdf has been created\n"
     ]
    }
   ],
   "source": [
    "plot_losses(losses_even,outmodel+\"_losses_even\",\"Even NN\")\n",
    "plot_losses(losses_odd,outmodel+\"_losses_odd\",\"Odd NN\")\n",
    "plot_roc(f_even,test_features_even,test_labels_even,outmodel+\"_roc_even\",\"Even NN\")\n",
    "plot_roc(f_odd,test_features_odd,test_labels_odd,outmodel+\"_roc_odd\",\"Odd NN\")\n",
    "validation_plot(f_even,test_features_even,train_features_even,train_labels_even,test_labels_even,train_weights_even,test_weights_even,outmodel+\"_validation_even\")\n",
    "validation_plot(f_odd,test_features_odd,train_features_odd,train_labels_odd,test_labels_odd,train_weights_odd,test_weights_odd,outmodel+\"_validation_odd\")\n",
    "\n",
    "\n",
    "y_pred_even = f_even.predict(test_features_even).ravel()\n",
    "fpr_even, tpr_even, thresholds_even = roc_curve(test_labels_even,y_pred_even)\n",
    "auc_nom_even = auc(fpr_even,tpr_even)\n",
    "\n",
    "y_pred_odd = f_odd.predict(test_features_odd).ravel()\n",
    "fpr_odd, tpr_odd, thresholds_odd = roc_curve(test_labels_odd,y_pred_odd)\n",
    "auc_nom_odd = auc(fpr_odd,tpr_odd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2bfd7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVEN AUC: 0.960139602\n",
      "ODD AUC: 0.9738134806000001\n",
      "Saved model to disk\n",
      "Saved model timestamp: models/fclass_full_v01conv_50000each_equWeight\n",
      "Trained on data: full_v01conv. test nonstand\n",
      "Saved loss: models/losses_full_v01conv_50000each_equWeight.npz\n"
     ]
    }
   ],
   "source": [
    "datafile = version+'conv. test nonstand'\n",
    "#####################################################\n",
    "# Save model \n",
    "#####################################################\n",
    "model_json_classif_even = f_even.to_json()\n",
    "with open(\"./models/fclass_\"+outmodel+\"_even.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json_classif_even)\n",
    "f_even.save_weights(\"./models/fclass_\"+outmodel+\"_even.h5\")\n",
    "np.savez(\"./models/losses_\"+outmodel+\"_even.npz\",losses=losses_even)\n",
    "\n",
    "model_json_classif_odd = f_odd.to_json()\n",
    "with open(\"./models/fclass_\"+outmodel+\"_odd.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json_classif_odd)\n",
    "f_odd.save_weights(\"./models/fclass_\"+outmodel+\"_odd.h5\")\n",
    "np.savez(\"./models/losses_\"+outmodel+\"_odd.npz\",losses=losses_odd)\n",
    "\n",
    "print(\"EVEN AUC: \"+str(auc_nom_even))\n",
    "print(\"ODD AUC: \"+str(auc_nom_odd))\n",
    "print(\"Saved model to disk\")\n",
    "print(\"Saved model timestamp: models/fclass_\"+outmodel)\n",
    "print(\"Trained on data: \"+datafile)\n",
    "print(\"Saved loss: models/losses_\"+outmodel+\".npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0e7eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345ff4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0315920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##seeing what a naive prediction would give:\n",
    "np.sum(train_labels_even)/len(train_labels_even), np.sum(test_labels_even)/len(test_labels_even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bfbbaa07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1384495733524379"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with weights\n",
    "np.sum(np.multiply(train_labels_even*1,train_weights_even))/np.sum(train_weights_even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5956fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
