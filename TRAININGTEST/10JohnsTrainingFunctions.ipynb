{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4065086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mine\n",
    "import uproot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boost_histogram as bh\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "# import atlasplots as ap\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "138ec1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 21:57:55.812473: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cvmfs/sft.cern.ch/lcg/releases/MCGenerators/thepeg/2.2.3-6fa5c/x86_64-centos7-gcc11-opt/lib/ThePEG:/cvmfs/sft.cern.ch/lcg/releases/MCGenerators/herwig++/7.2.3-c1d8e/x86_64-centos7-gcc11-opt/lib/Herwig:/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/jaxlib/mlir/_mlir_libs:/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/torch/lib:/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/onnxruntime/capi/:/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow:/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow/contrib/tensor_forest:/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow/python/framework:/cvmfs/sft.cern.ch/lcg/releases/java/11.0.14p1-8284a/x86_64-centos7-gcc11-opt/jre/lib/amd64:/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib64:/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/11.3.0-ad0f5/x86_64-centos7/lib:/cvmfs/sft.cern.ch/lcg/releases/gcc/11.3.0-ad0f5/x86_64-centos7/lib64:/cvmfs/sft.cern.ch/lcg/releases/binutils/2.37-355ed/x86_64-centos7/lib:/usr/local/lib/:/cvmfs/sft.cern.ch/lcg/releases/R/4.1.2-23baf/x86_64-centos7-gcc11-opt/lib64/R/library/readr/rcon\n",
      "2023-07-17 21:57:55.812532: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.28/00\n"
     ]
    }
   ],
   "source": [
    "#John's\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from datetime import datetime\n",
    "import statistics as stat\n",
    "import ROOT\n",
    "now = datetime.utcnow().strftime(\"%y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b61f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "# setting path\n",
    "sys.path.append('..')\n",
    " \n",
    "# importing\n",
    "import atlasplots as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81282fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mc20_clean = pickle.load(open('../picklefiles/df_mc20_clean.pickle', 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "# #converted and unconverted\n",
    "# df_conv = df_mc20_clean[df_mc20_clean.y_truth_convType == 0]\n",
    "# df_conv.index = list(range(len(df_conv))) #resetting indicies\n",
    "# df_unconv = df_mc20_clean[df_mc20_clean.y_truth_convType == 1]\n",
    "# df_unconv.index = list(range(len(df_unconv))) #resetting indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8669d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #SEPARATING EVEN AND ODD\n",
    "\n",
    "# def evenodd(df_name):\n",
    "#     '''separates input dataframe df_name into even events and odd events, by index'''\n",
    "#     evenlist = []\n",
    "#     oddlist = []\n",
    "#     for i in range(len(df_name)):\n",
    "# #         print(i)\n",
    "#         if i%2 == 0:\n",
    "#             evenlist.append(i)\n",
    "#         else:\n",
    "#             oddlist.append(i)\n",
    "            \n",
    "#     even = df_name.loc[evenlist]\n",
    "#     odd =  df_name.loc[oddlist]\n",
    "    \n",
    "#     return even, odd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "636e6d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_evenc,df_oddc = evenodd(df_conv)\n",
    "# df_evenu, df_oddu = evenodd(df_unconv)\n",
    "\n",
    "# df_evenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b5e9d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'BACKW25mil_TESTwWEIGHT'\n",
    "converted = True   #False for unconverted, True for converted    ##ACTUALLY FIX THIS TO DO SOMETHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b7a8805",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evenc = pickle.load(open('../picklefiles/'+version+'df_mc20_conv_even.pickle', 'rb'))\n",
    "df_oddc = pickle.load(open('../picklefiles/'+version+'df_mc20_conv_odd.pickle', 'rb'))\n",
    "# df_evenu = pickle.load(open('../picklefiles/'+version+'df_mc20_unconv_even.pickle', 'rb'))\n",
    "# df_oddu = pickle.load(open('../picklefiles/'+version+'df_mc20_unconv_odd.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9005e3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_stand = ['HadLeakage_stand', 'y_Reta_stand', 'y_Rphi_stand', 'y_weta2_stand',\n",
    "                   'y_wtots1_stand', 'y_weta1_stand', 'y_fracs1_stand', 'y_deltae_stand',\n",
    "                   'y_Eratio_stand', 'y_f1_stand']\n",
    "features = ['HadLeakage', 'y_Reta', 'y_weta2', 'y_Rphi', 'y_wtots1', \n",
    "            'y_weta1', 'y_fracs1', 'y_deltae', 'y_Eratio', 'y_f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b9b7d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR NOW just doing **conv.**  variables\n",
    "featlist = features_stand   # either features or features_stand \n",
    "weightstr = 'finalWeight'   #either 'finalWeight' for E_T and eta weighting or 'goodWeight' for not\n",
    "\n",
    "\n",
    "# for converted. (##add in option to change later)\n",
    "train_features_even = np.array(df_evenc[featlist])\n",
    "train_labels_even   = np.array(df_evenc['y_isTruthMatchedPhoton'])\n",
    "train_weights_even  = np.array(df_evenc[weightstr])\n",
    "test_features_even = np.array(df_oddc[featlist])\n",
    "test_labels_even   = np.array(df_oddc['y_isTruthMatchedPhoton'])\n",
    "test_weights_even  = np.array(df_oddc[weightstr])\n",
    "\n",
    "train_features_odd = np.array(df_oddc[featlist])\n",
    "train_labels_odd   = np.array(df_oddc['y_isTruthMatchedPhoton'])\n",
    "train_weights_odd  = np.array(df_oddc[weightstr])\n",
    "test_features_odd = np.array(df_evenc[featlist])\n",
    "test_labels_odd   = np.array(df_evenc['y_isTruthMatchedPhoton'])\n",
    "test_weights_odd  = np.array(df_evenc[weightstr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06c8a4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15380734, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_even.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82aeee10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_features,train_labels,train_weights,valid_features,valid_labels,valid_weights):\n",
    "    \"\"\"\n",
    "    Trains a binary classification model using the provided training and validation data.\n",
    "\n",
    "    Args:\n",
    "        train_features (numpy.ndarray): The input features for training the model.\n",
    "        train_labels (numpy.ndarray): The target labels for training the model.\n",
    "        train_weights (numpy.ndarray): The sample weights for training the model.\n",
    "        valid_features (numpy.ndarray): The input features for validating the model.\n",
    "        valid_labels (numpy.ndarray): The target labels for validating the model.\n",
    "        valid_weights (numpy.ndarray): The sample weights for validating the model.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the trained model and a dictionary of loss and accuracy values during training.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = tf.keras.layers.Input(dtype=tf.float64,shape=(train_features.shape[1],))\n",
    "    Dx = inputs\n",
    "    Dx = tf.keras.layers.BatchNormalization()(Dx)\n",
    "    Dx = tf.keras.layers.Dense(512,input_shape = (train_features.shape[1],))(Dx)\n",
    "    Dx = tf.keras.layers.LeakyReLU()(Dx)\n",
    "    Dx = tf.keras.layers.Dense(512,input_shape = (train_features.shape[1],))(Dx)\n",
    "    Dx = tf.keras.layers.LeakyReLU()(Dx)\n",
    "    Dx = tf.keras.layers.Dense(512,input_shape = (train_features.shape[1],))(Dx)\n",
    "    Dx = tf.keras.layers.Dense(1,activation=\"sigmoid\")(Dx)\n",
    "    f = tf.keras.models.Model([inputs],[Dx])\n",
    "\n",
    "    print('Classifier Summary')\n",
    "    f.summary()\n",
    "\n",
    "    ###########################################\n",
    "    # Train model\n",
    "    ############################################\n",
    "    f.compile(loss = tf.keras.losses.binary_crossentropy, optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5),metrics=[\"accuracy\"])\n",
    "\n",
    "    callback_es = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience = 10)\n",
    "    callback_nan = tf.keras.callbacks.TerminateOnNaN()\n",
    "\n",
    "    losses = {\"train\":[],\"accuracy\":[],\"validation\":[]}\n",
    "    hist = f.fit(x=train_features,\n",
    "           y=train_labels,\n",
    "           sample_weight=np.abs(train_weights),\n",
    "           callbacks=[callback_nan,callback_es],\n",
    "           batch_size=10000,    #was originally 256\n",
    "           epochs=200,\n",
    "           verbose=1,\n",
    "           validation_data=(valid_features,valid_labels,np.abs(valid_weights)))\n",
    "    losses[\"train\"].append(hist.history['loss'])\n",
    "    losses[\"accuracy\"].append(hist.history['accuracy'])\n",
    "    losses[\"validation\"].append(hist.history['val_loss'])\n",
    "\n",
    "    return f,losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75e0bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(losses,name,label):\n",
    "    \"\"\"\n",
    "    Plots the training and validation losses over epochs.\n",
    "\n",
    "    Args:\n",
    "        losses (dict): A dictionary containing the training and validation losses.\n",
    "        name (str): The name of the plot file to be saved.\n",
    "        label (str): The label for the plot.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    train_losses = losses['train']\n",
    "    validation_losses = losses['validation']\n",
    "    fig1, ax1 = plt.subplots(1)\n",
    "    plt.plot(range(len(train_losses[0])), train_losses[0], color=\"blue\",label=\"Training Loss\")\n",
    "    plt.plot(range(len(validation_losses[0])), validation_losses[0],color=\"red\",label='Validation Loss')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.title.set_text(label)\n",
    "    ax1.text(0.85, 0.77, 'ATLAS Internal', weight='bold',horizontalalignment='center', verticalalignment='center', transform=ax1.transAxes)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    fig1.savefig(\"plots/\"+name+\".pdf\",bbox_inches='tight')\n",
    "    plt.clf()\n",
    "    plt.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03913fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(model,test_features,test_labels,name,label):\n",
    "    \"\"\"\n",
    "    Plots the Receiver Operating Characteristic (ROC) curve for a binary classification model.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): The trained model used for prediction.\n",
    "        test_features (numpy.ndarray): The input features for testing the model.\n",
    "        test_labels (numpy.ndarray): The true labels for the test data.\n",
    "        name (str): The name of the plot file to be saved.\n",
    "        label (str): The label for the plot.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Raises:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(test_features).ravel()\n",
    "\n",
    "    # Compute the false positive rate, true positive rate, and thresholds for the ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(test_labels,y_pred)\n",
    "\n",
    "    f,ax = plt.subplots(1)\n",
    "    plt.plot([1,0],[0,1],'k--')\n",
    "    plt.plot(1-fpr, tpr)\n",
    "    plt.xlabel('Bkg Rejection')\n",
    "    plt.ylabel('Signal Efficiency')\n",
    "    plt.title(label)\n",
    "    plt.text(0.85, 0.95, 'ATLAS Internal', weight='bold',horizontalalignment='center', verticalalignment='center')\n",
    "    #plt.show()\n",
    "    f.savefig(\"plots/\"+name+\".pdf\",bbox_inches='tight')\n",
    "    plt.clf()\n",
    "    plt.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1d5d337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_plot(model,test_features,train_features,train_labels,test_labels,train_weights,test_weights,name):\n",
    "    \"\"\"\n",
    "    Creates a validation plot comparing the output of a neural network model for signal and background events.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): The trained model used for prediction.\n",
    "        test_features (numpy.ndarray): The input features for testing the model.\n",
    "        train_features (numpy.ndarray): The input features for training the model.\n",
    "        train_labels (numpy.ndarray): The target labels for training the model.\n",
    "        test_labels (numpy.ndarray): The target labels for testing the model.\n",
    "        train_weights (numpy.ndarray): The sample weights for training the model.\n",
    "        test_weights (numpy.ndarray): The sample weights for testing the model.\n",
    "        name (str): The name of the plot file to be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Raises:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(test_features).ravel()\n",
    "    y_pred_train = model.predict(train_features).ravel()\n",
    "    ROOT.gStyle.SetOptStat(0)\n",
    "    hist_sig = ROOT.TH1F(\"h_sig\",\";NN output; Normalized Events\",21,0,1.1)\n",
    "    hist_bkg = ROOT.TH1F(\"h_bkg\",\";NN output;Normalized Events\",21,0,1.1)\n",
    "    hist_sig_train = ROOT.TH1F(\"h_sig_train\",\"NN output;Normalized Events\",21,0,1.1)\n",
    "    hist_bkg_train = ROOT.TH1F(\"h_bkg_train\",\"NN output;Normalized Events\",21,0,1.1)\n",
    "\n",
    "    for i in range(len(test_features)):\n",
    "        if (test_labels[i]):\n",
    "            hist_sig.Fill(y_pred[i],test_weights[i])\n",
    "        else:\n",
    "            hist_bkg.Fill(y_pred[i],test_weights[i])\n",
    "\n",
    "    for i in range(len(train_features)):\n",
    "        if (train_labels[i]):\n",
    "            hist_sig_train.Fill(y_pred_train[i],train_weights[i])\n",
    "        else:\n",
    "            hist_bkg_train.Fill(y_pred_train[i],train_weights[i])\n",
    "\n",
    "    can = ROOT.TCanvas(\"can\",\"can\",800,600)\n",
    "\n",
    "    hist_sig.SetLineColor(1)\n",
    "    hist_sig.SetFillColor(1)\n",
    "    hist_sig.SetFillStyle(3005)\n",
    "    hist_sig.SetMarkerStyle(0)\n",
    "    hist_bkg.SetLineColor(8)\n",
    "    hist_bkg.SetFillColor(8)\n",
    "    hist_bkg.SetMarkerStyle(0)\n",
    "    hist_sig_train.SetMarkerColor(1)\n",
    "    hist_sig_train.SetLineColor(1)\n",
    "    hist_sig_train.SetMarkerSize(1)\n",
    "    hist_sig_train.SetMarkerStyle(8)\n",
    "    hist_bkg_train.SetMarkerColor(209)\n",
    "    hist_bkg_train.SetLineColor(209)\n",
    "    hist_bkg_train.SetMarkerStyle(8)\n",
    "    h = hist_bkg.DrawNormalized(\"HIST E\")\n",
    "    h.SetMinimum(0)\n",
    "    h.SetMaximum(h.GetMaximum()*3)\n",
    "    hist_sig.DrawNormalized(\"HIST SAME E\")\n",
    "    hist_bkg_train.DrawNormalized(\"pe SAME\")\n",
    "    hist_sig_train.DrawNormalized(\"pe SAME\")\n",
    "    leg = ROOT.TLegend(0.6,0.6,0.95,0.9)\n",
    "    leg.SetTextSize(.035)\n",
    "    leg.AddEntry(hist_sig_train,\"MC Signal (train)\",\"pe\")\n",
    "    leg.AddEntry(hist_bkg_train,\"MC Background (train)\",\"pe\")\n",
    "    leg.AddEntry(hist_sig,\"MC Signal (test)\",\"F\")\n",
    "    leg.AddEntry(hist_bkg,\"MC Background (test)\",\"F\")\n",
    "    leg.SetBorderSize(0)\n",
    "    leg.Draw()\n",
    "#     ROOT.ATLASLabel(0.2,0.88,\"Internal\");   \n",
    "    can.Print(\"plots/\"+name+\".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa0e719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62b12b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6987840112181902, 0.6987514834306011)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##seeing what a naive prediction would give:\n",
    "np.sum(train_labels_even)/len(train_labels_even), np.sum(test_labels_even)/len(test_labels_even)    #no weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7aa55cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000000000000306"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.multiply(train_labels_even*1,train_weights_even))/np.sum(train_weights_even)  #with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57530af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94638be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'train'\n",
    "outmodel = version+'conv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066b3a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Summary\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               5632      \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 531,497\n",
      "Trainable params: 531,477\n",
      "Non-trainable params: 20\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "1539/1539 [==============================] - ETA: 0s - loss: 3572.3416 - accuracy: 0.7960"
     ]
    }
   ],
   "source": [
    "#actually using the functions\n",
    "if method == 'train':\n",
    "    f_even, losses_even = train_model(train_features_even,train_labels_even,train_weights_even,test_features_even,test_labels_even,test_weights_even)\n",
    "    f_odd, losses_odd = train_model(train_features_odd,train_labels_odd,train_weights_odd,test_features_odd,test_labels_odd,test_weights_odd)\n",
    "\n",
    "#     plot_losses(losses_even,outmodel+\"_losses_even\",\"Even NN\")\n",
    "#     plot_losses(losses_odd,outmodel+\"_losses_odd\",\"Odd NN\")\n",
    "#     plot_roc(f_even,test_features_even,test_labels_even,outmodel+\"_roc_even\",\"Even NN\")\n",
    "#     plot_roc(f_odd,test_features_odd,test_labels_odd,outmodel+\"_roc_odd\",\"Odd NN\")\n",
    "#     validation_plot(f_even,test_features_even,train_features_even,train_labels_even,test_labels_even,train_weights_even,test_weights_even,outmodel+\"_validation_even\")\n",
    "#     validation_plot(f_odd,test_features_odd,train_features_odd,train_labels_odd,test_labels_odd,train_weights_odd,test_weights_odd,outmodel+\"_validation_odd\")\n",
    "\n",
    "\n",
    "#     y_pred_even = f_even.predict(test_features_even).ravel()\n",
    "#     fpr_even, tpr_even, thresholds_even = roc_curve(test_labels_even,y_pred_even)\n",
    "#     auc_nom_even = auc(fpr_even,tpr_even)\n",
    "\n",
    "#     y_pred_odd = f_odd.predict(test_features_odd).ravel()\n",
    "#     fpr_odd, tpr_odd, thresholds_odd = roc_curve(test_labels_odd,y_pred_odd)\n",
    "#     auc_nom_odd = auc(fpr_odd,tpr_odd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411282ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(losses_even,outmodel+\"_losses_even\",\"Even NN\")\n",
    "plot_losses(losses_odd,outmodel+\"_losses_odd\",\"Odd NN\")\n",
    "plot_roc(f_even,test_features_even,test_labels_even,outmodel+\"_roc_even\",\"Even NN\")\n",
    "plot_roc(f_odd,test_features_odd,test_labels_odd,outmodel+\"_roc_odd\",\"Odd NN\")\n",
    "validation_plot(f_even,test_features_even,train_features_even,train_labels_even,test_labels_even,train_weights_even,test_weights_even,outmodel+\"_validation_even\")\n",
    "validation_plot(f_odd,test_features_odd,train_features_odd,train_labels_odd,test_labels_odd,train_weights_odd,test_weights_odd,outmodel+\"_validation_odd\")\n",
    "\n",
    "\n",
    "y_pred_even = f_even.predict(test_features_even).ravel()\n",
    "fpr_even, tpr_even, thresholds_even = roc_curve(test_labels_even,y_pred_even)\n",
    "auc_nom_even = auc(fpr_even,tpr_even)\n",
    "\n",
    "y_pred_odd = f_odd.predict(test_features_odd).ravel()\n",
    "fpr_odd, tpr_odd, thresholds_odd = roc_curve(test_labels_odd,y_pred_odd)\n",
    "auc_nom_odd = auc(fpr_odd,tpr_odd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bfd7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = version+'conv. test nonstand'\n",
    "#####################################################\n",
    "# Save model \n",
    "#####################################################\n",
    "model_json_classif_even = f_even.to_json()\n",
    "with open(\"./models/fclass_\"+outmodel+\"_even.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json_classif_even)\n",
    "f_even.save_weights(\"./models/fclass_\"+outmodel+\"_even.h5\")\n",
    "np.savez(\"./models/losses_\"+outmodel+\"_even.npz\",losses=losses_even)\n",
    "\n",
    "model_json_classif_odd = f_odd.to_json()\n",
    "with open(\"./models/fclass_\"+outmodel+\"_odd.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json_classif_odd)\n",
    "f_odd.save_weights(\"./models/fclass_\"+outmodel+\"_odd.h5\")\n",
    "np.savez(\"./models/losses_\"+outmodel+\"_odd.npz\",losses=losses_odd)\n",
    "\n",
    "print(\"EVEN AUC: \"+str(auc_nom_even))\n",
    "print(\"ODD AUC: \"+str(auc_nom_odd))\n",
    "print(\"Saved model to disk\")\n",
    "print(\"Saved model timestamp: models/fclass_\"+outmodel)\n",
    "print(\"Trained on data: \"+datafile)\n",
    "print(\"Saved loss: models/losses_\"+outmodel+\".npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0e7eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345ff4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0315920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6987840112181902, 0.6987514834306011)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##seeing what a naive prediction would give:\n",
    "np.sum(train_labels_even)/len(train_labels_even), np.sum(test_labels_even)/len(test_labels_even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfbbaa07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000000000000306"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.multiply(train_labels_even*1,train_weights_even))/np.sum(train_weights_even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5956fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
